{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Rhwe20CPrSOP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some tensor exercises to regain familiarity w PyTorch**"
      ],
      "metadata": {
        "id": "o9_r2SWwr0hY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate random tensor, scalar\n",
        "random_tensor = torch.rand(size = (3, 4))\n",
        "random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvHtbdUKrxqE",
        "outputId": "744f232c-82cc-4b28-d046-ba9dfef3ab74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5600, 0.0561, 0.4043, 0.7830],\n",
              "        [0.8432, 0.1763, 0.0597, 0.8329],\n",
              "        [0.5180, 0.9345, 0.3740, 0.5444]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check dimensions\n",
        "random_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0YRijScsCUJ",
        "outputId": "4c3a8222-91f3-4723-918c-b4994cc8017c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZI_4GU0sJk3",
        "outputId": "71ad354b-7055-4a81-ae25-1578433346cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the dimensions of a tensor, count the number of square brackets [ on the outside (i.e. the leftmost square brackets).\n",
        "\n",
        "To think about tensor shapes, we can think about the first dimension as the \"count\". For example, a tensor item of shape [2, 4, 5] can be interpreted as:\n",
        "- 2 matrices with shape [4, 5]\n",
        "- where [4, 5] represents 4 vectors (rows) with 5 datapoints\n",
        "\n",
        "A tensor item of shape [3, 4] can subsequently be interpreted as a matrix with 3 vectors (rows), each having shape 4 (aka 4 elements)."
      ],
      "metadata": {
        "id": "FNxIt012tqZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_matrix = torch.tensor([[[1, 3, 4, 5],\n",
        "                               [2, 4, 5, 5],\n",
        "                               [1, 0, 9, 9]]])"
      ],
      "metadata": {
        "id": "X0GhhlKitc8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The matrix above has 3 dimensions, and appears to have shape [1, 3, 4] (one matrix with 3 vectors, where each vector contains 4 elements)."
      ],
      "metadata": {
        "id": "jkbeCU6wwBxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxHFWSq0wAMj",
        "outputId": "406c5589-d11b-455c-ec51-a7acc84f6575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch also supports lots of the same implementations as numpy:\n",
        "- torch.zeros(size = ())\n",
        "- torch.ones(size = ())\n",
        "- torch.arange(start =, stop =, step =)\n",
        "\n",
        "Some **attributes** that can be specified when in torch.tensor() include:\n",
        "- dtype (default: float32)\n",
        "- device (default: None)"
      ],
      "metadata": {
        "id": "7PTSdLoTwdmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_matrix.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2A9LG_TwLgt",
        "outputId": "7778398d-0b7c-4d5f-b274-aa9ad2591c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor Operations**\n",
        "- Adding, subtracting and multiplying can be achieved via broadcasting\n",
        "- Can perform element-wise multiplication via torch.mul()\n",
        "- Can perform matrix multiplication with matrix @ matrix or torch.matmul()\n",
        "- Two methods of transpose: torch.transpose(input, dim0, dim1) or tensor.T\n",
        "\n",
        "**Aggregate Operations**\n",
        "- Mean: convert into float32, then use .mean()\n",
        "- Can directly implement tensor.min(), .max(), and .sum()\n",
        "- We can also return the **index** of where the max and min are found using .argmax() and .argmin()\n",
        "\n",
        "**Changing Type of Tensor**\n",
        "- Given an existing tensor, we can use tensor.type()"
      ],
      "metadata": {
        "id": "-sXjoRi5x33q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 3, 5, 5, 2, 6, 1])\n",
        "\n",
        "tensor.type(torch.float32).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_FcyeNOx18x",
        "outputId": "d652ef9f-85e2-4a02-a81d-38762412674f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.2857)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD1KCXjG9h5R",
        "outputId": "cea06129-9d81-448e-f2ad-8425732b3e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quick note on datatypes**\n",
        "- These are in charge of precision for storing tensor in memory\n",
        "- Ex) 64-bit precision is more than 32-bit\n",
        "- Less precise computations take less time and lead to a smaller overall model, but can sacrifice accuracy"
      ],
      "metadata": {
        "id": "MopkeLFz-BDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_16 = torch.arange(10.0, 100.0, 10.0).type(torch.float16)\n",
        "tensor_16.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKOXC7qp9vAQ",
        "outputId": "85a73575-5ede-44f4-a318-267c1bbf785d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reshaping without changing values**\n",
        "- torch.reshape(input, shape) or torch.Tensor.reshape reshapes input to a compatible shape\n",
        "- Tensor.view(shape) provides view of original tensor in different shape (but same data)\n",
        "- torch.stack(tensors, dim) stacks tensors along a specific dimension\n",
        "- torch.squeeze(tensor) removes all dimensions w value 1\n",
        "- torch.unsqueeze(tensor, dim) adds a value of 1 at dim\n",
        "- torch.permute(tensor, dims) returns original input with dimensions permuted to dims"
      ],
      "metadata": {
        "id": "iEHxiIVRKH9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(1, 8)\n",
        "x.shape"
      ],
      "metadata": {
        "id": "MvqaFQPEKDrR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834b5db5-3c35-4b97-9fdb-2983c36b2453"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add a dimension using reshape\n",
        "x_reshaped = x.reshape(1, 7, 1)\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkxZHJXk9W3j",
        "outputId": "97293675-2b81-4243-aa7a-e588f0f758bc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1],\n",
              "          [2],\n",
              "          [3],\n",
              "          [4],\n",
              "          [5],\n",
              "          [6],\n",
              "          [7]]]),\n",
              " torch.Size([1, 7, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's look at it in a new view (this changes the tensor if we assign it to a new variable)\n",
        "x_reshaped.view(1, 7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ve7IkDTv9jza",
        "outputId": "6d67ab0e-cce6-4772-a7cc-b822a689bbad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3, 4, 5, 6, 7]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's perform some **operations on a 1D tensor**.\n",
        "- Here, there is only one dimension, so we can only perform operations on dim = 0 (the horizontal dimension)\n",
        "- Summing over a 1D tensor gives the sum of all values in the tensor\n",
        "- Stacking **adds a dimension**"
      ],
      "metadata": {
        "id": "zQpRQsK4-18Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we can start with the tensor we generated earlier\n",
        "x, x.ndim, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE21M1cLBOEF",
        "outputId": "106f8922-c19f-4e38-e199-fe687c4746e3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4, 5, 6, 7]), 1, torch.Size([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.sum(dim = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA-TKioOBWWh",
        "outputId": "1038700c-140a-4bf7-a67a-a1dfb913d5b4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(28)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_1d = torch.stack([x, x, x])\n",
        "\n",
        "stacked_1d, stacked_1d.shape, stacked_1d.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWqho3F4Eitd",
        "outputId": "e6e7ce53-988c-417a-e4b3-30ec89fc3841"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2, 3, 4, 5, 6, 7],\n",
              "         [1, 2, 3, 4, 5, 6, 7],\n",
              "         [1, 2, 3, 4, 5, 6, 7]]),\n",
              " torch.Size([3, 7]),\n",
              " 2)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's try on a **2D tensor**\n",
        "- Now, we have dimensions 0 and 1, so we can perform operations on these dimensions\n",
        "- We can consider dim = 0 as the \"outermost dimension\". This means \"the largest chunk\" in the tensor\n",
        "- We consider dim = 1 as the \"innermost dimension\", aka the smallest building block in the tensor\n",
        "\n",
        "For example, .sum(dim = 0) sums over the \"largest chunks\", which would be the individual matrices within the tensor (i.e. [1, 2, 3] and [3, 5, 7]. We could express this addition like item-wise addition:\n",
        "\n",
        "```\n",
        "  [1, 2, 3]\n",
        "+ [3, 5, 7]\n",
        "= [4, 7, 10]\n",
        "```\n",
        "The resulting sum is a 1D tensor with shape 3\n",
        "\n",
        "In contrast, .sum(dim = 1) sums over the \"smallest chunks\". In this case, that would be the numbers within the samller matrices. We can think of this as \"within-group\" addition:\n",
        "\n",
        "\n",
        "```\n",
        "[1 + 2 + 3, 3 + 5 + 7] = [6, 15]\n",
        "```\n",
        "The resulting sum is a 1D tensor with shape 2\n",
        "\n",
        "\n",
        "- We can also access a tensor's innermost dimension with dim = -1 (similar to list indexing)\n",
        "\n"
      ],
      "metadata": {
        "id": "eNZLC5g9BoJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tens_2d = torch.tensor([[1, 2, 3], [3, 5, 7]])\n",
        "tens_2d, tens_2d.ndim, tens_2d.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uot3kSSCBngK",
        "outputId": "d9e3db93-879b-4496-ca5b-e721bdd18457"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2, 3],\n",
              "         [3, 5, 7]]),\n",
              " 2,\n",
              " torch.Size([2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this will sum over the \"largest chunks\"\n",
        "dim0_sum = tens_2d.sum(dim = 0)\n",
        "\n",
        "print(\"Dimension 0\")\n",
        "print(dim0_sum, dim0_sum.shape, dim0_sum.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9rnrjmpCnFA",
        "outputId": "843bfe92-b516-4b56-9748-6d4d51302c94"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension 0\n",
            "tensor([ 4,  7, 10]) torch.Size([3]) 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this sums over the \"smallest chunks\" aka the individual numbers\n",
        "dim1_sum = tens_2d.sum(dim = 1)\n",
        "\n",
        "print(\"Dimension 1\")\n",
        "print(dim1_sum, dim1_sum.shape, dim1_sum.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPmuTi0uD6s2",
        "outputId": "1d1ac426-25da-4e21-c314-7fa03ecaf973"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension 1\n",
            "tensor([ 6, 15]) torch.Size([2]) 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try stacking for a 2D tensor\n",
        "\n",
        "- Here, stacking along dim = 0 adds a dimension to the front. We stack along the axis of the \"largest chunks\"\n",
        "- Stacking along axis dim = 1 takes the smaller units within the matrices and stacks the individual \"vectors\"\n",
        "- Stacking along both dim = 0, 1 results in the same shape and dim\n",
        "\n",
        "- However, stacking along dim = 2 is the transpose of dim = 1. This is the innermost dimension."
      ],
      "metadata": {
        "id": "YhkzsjruER5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim0_stack = torch.stack([tens_2d, tens_2d], dim = 0)\n",
        "dim0_stack, dim0_stack.shape, dim0_stack.ndim\n",
        "\n",
        "## shape interpretation: 2 matrices of size [2, 3] (2 vectors, 3 elements per vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4qgoVfFERc0",
        "outputId": "9c305819-f839-4cc2-d6e3-43e7568965d8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [3, 5, 7]],\n",
              " \n",
              "         [[1, 2, 3],\n",
              "          [3, 5, 7]]]),\n",
              " torch.Size([2, 2, 3]),\n",
              " 3)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim1_stack = torch.stack([tens_2d, tens_2d], dim = 1)\n",
        "dim1_stack, dim1_stack.shape, dim1_stack.ndim\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H4C0ss9F3zB",
        "outputId": "df38eacc-2102-451c-c7a7-0bcafe9f9ed0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [1, 2, 3]],\n",
              " \n",
              "         [[3, 5, 7],\n",
              "          [3, 5, 7]]]),\n",
              " torch.Size([2, 2, 3]),\n",
              " 3)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim2_stack = torch.stack([tens_2d, tens_2d], dim = 2)\n",
        "dim2_stack, dim2_stack.shape, dim2_stack.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXgdgzaNGVVH",
        "outputId": "50c44dd1-df50-4751-b69a-fe40c5380ad9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 1],\n",
              "          [2, 2],\n",
              "          [3, 3]],\n",
              " \n",
              "         [[3, 3],\n",
              "          [5, 5],\n",
              "          [7, 7]]]),\n",
              " torch.Size([2, 3, 2]),\n",
              " 3)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's work with 3D tensors !! We can use the same logic as our 2D tensors. To generate a 3D tensor, we should have three \"outermost\" brackets before reaching the first number.\n",
        "\n",
        "Analyzing the sums:\n",
        "- For summing along dim = 0, this is element-wise addition. We add the entire first matrix to the entire second matrix.\n",
        "\n",
        "```\n",
        "  [1, 2, 3] # first row of mat1\n",
        "+ [4, 5, 1] # first row of mat2\n",
        "= [5, 7, 4]\n",
        "and\n",
        "  [4, 2, 6] # second row of mat1\n",
        "+ [2, 2, 3] # second row of mat2\n",
        "= [6, 4, 9]\n",
        "```\n",
        "- For summing along dim = 1, we can think of this as \"within-matrix addition\". We sum the second-largest components (i.e. the vectors within the matrices) with each other\n",
        "\n",
        "```\n",
        "  [1, 2, 3] # first row of mat1\n",
        "+ [4, 2, 6] # second row of mat1\n",
        "= [5, 4, 9]\n",
        "```\n",
        "- For summing along dim = 2, we see that this is a \"individual sum\", and we sum up all the elements within the vectors.\n",
        "\n",
        "```\n",
        "[1 + 2 + 3], [4 + 2 + 6]\n",
        "[4 + 5 + 1], [2 + 2 + 3]\n",
        "= [6], [12]\n",
        "  [10], [7]\n",
        "```"
      ],
      "metadata": {
        "id": "MtcrDN9oJAGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tens_3d = torch.tensor([\n",
        "    [[1, 2, 3], [4, 2, 6]],\n",
        "    [[4, 5, 1], [2, 2, 3]]\n",
        "    ])\n",
        "\n",
        "tens_3d, tens_3d.shape, tens_3d.ndim\n",
        "\n",
        "## shape interpretation: 2 matrices of size [2, 3], aka two vectors with three entries each"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5tioW_tJh2V",
        "outputId": "bfc4e863-8cfe-4349-b2da-cc53d2806db3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 2, 6]],\n",
              " \n",
              "         [[4, 5, 1],\n",
              "          [2, 2, 3]]]),\n",
              " torch.Size([2, 2, 3]),\n",
              " 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this will sum over the \"largest chunks\"\n",
        "dim0_sum = tens_3d.sum(dim = 0)\n",
        "\n",
        "print(\"Dimension 0\")\n",
        "print(dim0_sum, dim0_sum.shape, dim0_sum.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmPCEOgYZH-M",
        "outputId": "82d78cd6-72e9-4a68-d6d8-5d84e6fffda1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension 0\n",
            "tensor([[5, 7, 4],\n",
            "        [6, 4, 9]]) torch.Size([2, 3]) 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim1_sum = tens_3d.sum(dim = 1)\n",
        "\n",
        "print(\"Dimension 1\")\n",
        "print(dim1_sum, dim1_sum.shape, dim1_sum.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i_KUp4CaJbB",
        "outputId": "47f55a3c-95ac-49d0-ecc9-bc047a02c378"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension 1\n",
            "tensor([[5, 4, 9],\n",
            "        [6, 7, 4]]) torch.Size([2, 3]) 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim2_sum = tens_3d.sum(dim = 2)\n",
        "\n",
        "print(\"Dimension 2\")\n",
        "print(dim2_sum, dim2_sum.shape, dim2_sum.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzr7DDIn_YD5",
        "outputId": "381eec52-ec4e-44aa-d490-8217d7c3d40d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension 2\n",
            "tensor([[ 6, 12],\n",
            "        [10,  7]]) torch.Size([2, 2]) 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's examine stacking:\n",
        "- As expected, stacking along dim = 0 simply stacks the outermost matrices together. Here, the outermost matrix is [2, 2, 3] or 2 x [2, 3]\n",
        "\n",
        "```\n",
        "[1, 2, 3],\n",
        "[4, 2, 6]\n",
        "\n",
        "[4, 5, 1],\n",
        "[2, 2, 3]\n",
        "```\n",
        "- Dim = 1 is the next-outermost dimension, which is reflected in the smaller [2, 3] matrices. Each of these [2, 3] matrices are stacked on top of each other.\n",
        "- Dim = 2 should refer to each of the 1x3 vectors within each [2, 3] matrix. Each of the individual vectors from one copy of tens_3d is stacked onto an individ. vector from the second copy. There are four individual vectors in dim = 2\n",
        "```\n",
        "[1, 2, 3],\n",
        "[4, 2, 6],\n",
        "[4, 5, 1],\n",
        "[2, 2, 3]\n",
        "```\n",
        "- Finally, dim = 3 refers to the individual numbers within each of the vectors (1, 2, 3, 4, 2, 6 .... 2, 3). These are \"stacked\", or combined with the corresponding number from the second copy of tens_3d."
      ],
      "metadata": {
        "id": "36JnkZOVcaQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim0_stack = torch.stack([tens_3d, tens_3d], dim = 0)\n",
        "dim0_stack, dim0_stack.shape, dim0_stack.ndim\n",
        "\n",
        "## shape interpretation: now 4-dims. 2 large matrices, with 2 smaller matrices inside. Each smaller matrix has shape [2, 3]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5rY9qYta0wX",
        "outputId": "e129fb72-2d71-4f25-d091-fa315d97f05d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[1, 2, 3],\n",
              "           [4, 2, 6]],\n",
              " \n",
              "          [[4, 5, 1],\n",
              "           [2, 2, 3]]],\n",
              " \n",
              " \n",
              "         [[[1, 2, 3],\n",
              "           [4, 2, 6]],\n",
              " \n",
              "          [[4, 5, 1],\n",
              "           [2, 2, 3]]]]),\n",
              " torch.Size([2, 2, 2, 3]),\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim1_stack = torch.stack([tens_3d, tens_3d], dim = 1)\n",
        "dim1_stack, dim1_stack.shape, dim1_stack.ndim\n",
        "\n",
        "## shape interpretation: now 4-dims. 2 large matrices, with 2 smaller matrices inside. Each smaller matrix has shape [2, 3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32NqjROoc4wu",
        "outputId": "a7d88402-a275-4b2c-b7d7-6b6636078f25"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[1, 2, 3],\n",
              "           [4, 2, 6]],\n",
              " \n",
              "          [[1, 2, 3],\n",
              "           [4, 2, 6]]],\n",
              " \n",
              " \n",
              "         [[[4, 5, 1],\n",
              "           [2, 2, 3]],\n",
              " \n",
              "          [[4, 5, 1],\n",
              "           [2, 2, 3]]]]),\n",
              " torch.Size([2, 2, 2, 3]),\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim2_stack = torch.stack([tens_3d, tens_3d], dim = 2)\n",
        "dim2_stack, dim2_stack.shape, dim2_stack.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkUU28RAfFdC",
        "outputId": "1ba8b822-1573-4408-de8f-302eb4d89945"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[1, 2, 3],\n",
              "           [1, 2, 3]],\n",
              " \n",
              "          [[4, 2, 6],\n",
              "           [4, 2, 6]]],\n",
              " \n",
              " \n",
              "         [[[4, 5, 1],\n",
              "           [4, 5, 1]],\n",
              " \n",
              "          [[2, 2, 3],\n",
              "           [2, 2, 3]]]]),\n",
              " torch.Size([2, 2, 2, 3]),\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim3_stack = torch.stack([tens_3d, tens_3d], dim = 3)\n",
        "dim3_stack, dim3_stack.shape, dim3_stack.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLeDB2Ogf9f1",
        "outputId": "867caa60-3026-4100-c3a4-72bee395a42b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[1, 1],\n",
              "           [2, 2],\n",
              "           [3, 3]],\n",
              " \n",
              "          [[4, 4],\n",
              "           [2, 2],\n",
              "           [6, 6]]],\n",
              " \n",
              " \n",
              "         [[[4, 4],\n",
              "           [5, 5],\n",
              "           [1, 1]],\n",
              " \n",
              "          [[2, 2],\n",
              "           [2, 2],\n",
              "           [3, 3]]]]),\n",
              " torch.Size([2, 2, 3, 2]),\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Indexing**\n",
        "- Indexing is similar to Python lists, going from outermost to innermost dimension.\n",
        "- Ex) tensor[0] accesses the 0th element of the outermost dimension. tensor[0][0] accesses the 0th element of the second-outermost dimension, and so forth\n",
        "- Similar to Python lists, adding a colon + comma selects all the values in that dimension\n",
        "- Ex) tensor[:, :, 1] takes the entire dim0, entire dim1, and the first index of dim2"
      ],
      "metadata": {
        "id": "Mfddg-FgjBDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(1, 10).reshape(1, 3, 3) # creating a 3D tensor\n",
        "\n",
        "x, x.shape, x.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaYhVCyrig-K",
        "outputId": "a525861b-709b-49e5-f3f1-2679aa2b3cba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]),\n",
              " 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEVNztR4jzXl",
        "outputId": "c2a5239c-7aba-4426-f84b-e73fc8ba1e70"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZirJu5QkAh_",
        "outputId": "a3409cb3-9117-4a7a-8faa-3d0504d5c2a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0][1][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBcjxDGJkDLa",
        "outputId": "bab1d6f7-065e-4a19-a6dc-e26e5195efe3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:, 1, 1] # this should return [5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGOoqbdskFl-",
        "outputId": "b79b827d-0419-483d-fb86-00a18811bac4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:, :, 2] # this returns [3, 6, 9], aka the second element of all the vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_rCDJk7kMhC",
        "outputId": "9c6e638c-16ea-4700-98af-9e319627c627"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3, 6, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running on GPU for large scale calculations:\n",
        "1. Check if GPU is available\n",
        "2. Write device variable which can set to run on gpu if available"
      ],
      "metadata": {
        "id": "80-W3EHnl9Iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9CifTFVkZYh",
        "outputId": "358c2ca1-d67c-40ac-ebae-c3e3a9368532"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wYF_0v5Glhzp",
        "outputId": "e5b0bd28-1f28-46d4-d1cd-79c825184e70"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercises:"
      ],
      "metadata": {
        "id": "YyuBUP_-mjZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 random tensor\n",
        "\n",
        "rando = torch.rand(size = (7, 7))\n",
        "rando"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNrjjs1LmTXg",
        "outputId": "71c02292-1dbc-4b1b-a409-27bcae716956"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0457, 0.5235, 0.2222, 0.2548, 0.3591, 0.9179, 0.0644],\n",
              "        [0.0491, 0.4401, 0.8279, 0.2169, 0.1140, 0.7570, 0.6340],\n",
              "        [0.3988, 0.1262, 0.6524, 0.7222, 0.6510, 0.6468, 0.9578],\n",
              "        [0.0657, 0.7745, 0.9396, 0.1807, 0.3543, 0.3372, 0.4056],\n",
              "        [0.7353, 0.2378, 0.7191, 0.6935, 0.6947, 0.4327, 0.2974],\n",
              "        [0.3118, 0.3243, 0.1541, 0.3925, 0.3662, 0.7409, 0.5370],\n",
              "        [0.2067, 0.8930, 0.4838, 0.5705, 0.5794, 0.5639, 0.9413]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rando_2 = torch.rand(size = (1, 7))\n",
        "rando_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S36bB-VpmqBe",
        "outputId": "ca76d4ba-5b11-4d1d-912f-374b95c11cd7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9083, 0.9561, 0.8080, 0.8432, 0.5581, 0.6355, 0.6683]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 multiplication\n",
        "\n",
        "mult = torch.matmul(rando, rando_2.T)\n",
        "mult"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA_EmsYDmuom",
        "outputId": "44334c69-3aa0-4457-a751-8d432a41251e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.7633],\n",
              "        [2.2856],\n",
              "        [3.0334],\n",
              "        [2.3949],\n",
              "        [2.9225],\n",
              "        [2.0828],\n",
              "        [3.2244]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 seed\n",
        "\n",
        "random_seed = 0\n",
        "torch.manual_seed(seed = random_seed)\n",
        "\n",
        "rando = torch.rand(size = (7, 7))\n",
        "rando"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNO1AK_Cm1Dl",
        "outputId": "9b861e37-be9d-473b-a1a0-046057e25614"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901],\n",
              "        [0.8964, 0.4556, 0.6323, 0.3489, 0.4017, 0.0223, 0.1689],\n",
              "        [0.2939, 0.5185, 0.6977, 0.8000, 0.1610, 0.2823, 0.6816],\n",
              "        [0.9152, 0.3971, 0.8742, 0.4194, 0.5529, 0.9527, 0.0362],\n",
              "        [0.1852, 0.3734, 0.3051, 0.9320, 0.1759, 0.2698, 0.1507],\n",
              "        [0.0317, 0.2081, 0.9298, 0.7231, 0.7423, 0.5263, 0.2437],\n",
              "        [0.5846, 0.0332, 0.1387, 0.2422, 0.8155, 0.7932, 0.2783]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# need to reset the seed every time a new rand is called\n",
        "\n",
        "torch.random.manual_seed(seed = random_seed)\n",
        "\n",
        "rando_2 = torch.rand(size = (1, 7))\n",
        "rando_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPkUE-fgnRx9",
        "outputId": "eb969012-cbfb-435e-82c2-6bc04bc3b966"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mult = torch.matmul(rando, rando_2.T)\n",
        "mult"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBGtwsGrnaG7",
        "outputId": "b429840c-8e2a-4d8e-dbf1-d7f26716d2fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.5985],\n",
              "        [1.1173],\n",
              "        [1.2741],\n",
              "        [1.6838],\n",
              "        [0.8279],\n",
              "        [1.0347],\n",
              "        [1.2498]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4 gpu seed\n",
        "\n",
        "torch.cuda.manual_seed(seed = 1234)"
      ],
      "metadata": {
        "id": "1QUu8Fuynd4e"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 tensors on gpu\n",
        "\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "rando = torch.rand(size = (2, 3))\n",
        "rando_gpu = rando.to(device)\n",
        "\n",
        "rando2 = torch.rand(size = (2, 3))\n",
        "rando2_gpu = rando2.to(device)\n",
        "\n",
        "rando_gpu, rando2_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs5KY4RKn3CV",
        "outputId": "ec621ecf-c217-4eed-a580-debacf7b1e6e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0290, 0.4019, 0.2598],\n",
              "         [0.3666, 0.0583, 0.7006]], device='cuda:0'),\n",
              " tensor([[0.0518, 0.4681, 0.6738],\n",
              "         [0.3315, 0.7837, 0.5631]], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mult = torch.matmul(rando_gpu, rando2_gpu.T)\n",
        "mult"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbO-U-_an_sQ",
        "outputId": "654b7c36-ce62-4c35-a794-03c13c23bd91"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3647, 0.4709],\n",
              "        [0.5184, 0.5617]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"minimum: {torch.min(mult)}\")\n",
        "print(f\"maximum: {torch.max(mult)}\")\n",
        "print(f\"argmin: {torch.argmin(mult)}\")\n",
        "print(f\"argmax: {torch.argmax(mult)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH_7VTKKoarJ",
        "outputId": "bb30a9f5-9ec9-48c2-bac0-911695c34938"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minimum: 0.3647301495075226\n",
            "maximum: 0.5617256760597229\n",
            "argmin: 0\n",
            "argmax: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6 reshaping\n",
        "torch.manual_seed(7)\n",
        "\n",
        "rand = torch.rand(size = (1, 1, 1, 10))\n",
        "new_rand = torch.squeeze(rand)\n",
        "\n",
        "rand.shape, new_rand.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_1nvrp5oiXO",
        "outputId": "37425542-9e67-4d2e-bcbd-61546e996010"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 1, 10]), torch.Size([10]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand, new_rand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiWBW8Oqo_lT",
        "outputId": "e6041be6-b696-4f7f-e9ff-4e3d45be483c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
              "            0.3653, 0.8513]]]]),\n",
              " tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
              "         0.8513]))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d0Vj5xHapJ30"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}